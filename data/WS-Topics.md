
Workshop 1: Generative AI and SDLC for LLMs

- Generative AI and SDLC for LLMs
- What is Generative AI?
- Overview of the Software Development Lifecycle (SDLC) for LLM-powered applications
- Non-deterministic systems and why iteration is critical
- Key tools and frameworks for LLM-based applications
- Set up the foundational app (e.g., querying PDFs and generating responses)

Workshop 2: Prompt Engineering in the LLM SDLC

- Understanding API Knobs (e.g., temperature, top_p, max_tokens, system prompt, etc.)
- Basics of prompt engineering
- Iterative refinement of prompts to improve the output

Workshop 3: Evaluation and Iteration

- Systematic evaluation of LLM outputs (qualitative and quantitative approaches).
- Defining metrics for success (e.g., relevance, coherence, user satisfaction).
- Setting up feedback loops (e.g., thumbs-up/thumbs-down mechanisms).

Workshop 4: Observability and Debugging

- Observability basics: logging, tracing, and monitoring app performance.
- Debugging common LLM issues (e.g., hallucinations, API failures).
- Scaling observability: tools for production monitoring.

Workshop 5: Information Retrieval â€”> Agents

- What are embeddings, and why are they foundational?
- Introduction to vector stores and their role in generative AI
- Building retrieval-augmented generation (RAG) systems

Workshop 6: Structured Outputs, Function Calling, and Agentic Workflows

- Extracting structured outputs from unstructured data
- Use cases: parsing LinkedIn profiles, generating JSON responses
- Function calling: when and how to use it
- Agentic Workflows: Automate actions based on API responses (e.g., send an email).

Workshop 7: Multi-Agentic Workflows

- Advanced prompt optimization: dynamically adapting prompts for specific use cases.
- Multi-agent workflows: introducing LLMs that collaborate with APIs or other models.
- Future trends: open-source models, lightweight deployment, and more.

Workshop 8: Fine-tunning and production LLM Applications

- Fine-tuning basics: when to fine-tune vs. prompt engineering.
- Preparing datasets for fine-tuning: collection, cleaning, and formatting.
- Productionizing LLM apps: reliability, API scaling, and handling rate limits.

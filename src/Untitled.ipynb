{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaa9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import glob\n",
    "from process_transcript import chunk_workshop_transcript, count_tokens, robust_chunk_workshop\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "# Support both local and Modal paths - notebook compatible version\n",
    "# Check for Modal environment first, then use relative paths for local notebook\n",
    "if os.path.exists(\"/root/data\"):\n",
    "    DATA_DIR = \"/root/data\"\n",
    "    CHROMA_DB_PATH = \"/root/chroma_db\"\n",
    "else:\n",
    "    # For notebook environment, go up one directory from src to project root\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('/src'):\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "    DATA_DIR = os.path.join(project_root, \"data\")\n",
    "    CHROMA_DB_PATH = os.path.join(project_root, \"chroma_db\")\n",
    "\n",
    "COLLECTION_NAME = \"workshop_chunks_all\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "DEFAULT_MAX_TOKENS = 12000\n",
    "DEFAULT_MAX_CHUNKS = 5\n",
    "COMPLETION_MODEL = \"gpt-4o-mini\"\n",
    "EMBEDDING_MAX_TOKENS = 8000\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful workshop assistant.\n",
    "Answer questions based only on the workshop transcript sections provided.\n",
    "If you don't know the answer or can't find it in the provided sections, say so.\n",
    "When referencing information, mention which workshop(s) the information comes from.\"\"\"\n",
    "\n",
    "def discover_workshops(data_dir=DATA_DIR):\n",
    "    \"\"\"Discover all workshop VTT files in the data directory\"\"\"\n",
    "    try:\n",
    "        pattern = os.path.join(data_dir, \"*.vtt\")\n",
    "        vtt_files = glob.glob(pattern)\n",
    "        \n",
    "        workshops = {}\n",
    "        for vtt_file in vtt_files:\n",
    "            filename = os.path.basename(vtt_file)\n",
    "            workshop_id = filename.split('-')[0] if '-' in filename else filename.split('.')[0]\n",
    "            \n",
    "            workshops[workshop_id] = {\n",
    "                'id': workshop_id,\n",
    "                'filename': filename,\n",
    "                'path': vtt_file\n",
    "            }\n",
    "        \n",
    "        return workshops\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error discovering workshops: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e07dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_vtt = discover_workshops(data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c719eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pastor/projects/discord-chat-bot/data/WS5-C2.vtt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_vtt['WS5']['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edfc019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vtt_content(file_path):\n",
    "    \"\"\"Load VTT file and extract clean text content\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    content_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if (not line or \n",
    "            line == 'WEBVTT' or \n",
    "            '-->' in line or \n",
    "            re.match(r'^\\d+:\\d+:\\d+', line) or\n",
    "            re.match(r'^[A-Z]+(\\s*:.*)?$', line)):\n",
    "            continue\n",
    "        content_lines.append(line)\n",
    "    \n",
    "    return \" \".join(content_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e2831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_vtt = load_vtt_content(files_vtt['WS5']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b326c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(transcript_vtt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3dae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_wrap(string, n_chars=72):\n",
    "    # Wrap a string at the next space after n_chars\n",
    "    if len(string) < n_chars:\n",
    "        return string\n",
    "    else:\n",
    "        return string[:n_chars].rsplit(' ', 1)[0] + '\\n' + word_wrap(string[len(string[:n_chars].rsplit(' ', 1)[0])+1:], n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_wrap(character_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2421119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48daeda7fc4f45838678fc7ce384a309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291e32ec9cc9421aba29ad54efe6a64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed263b1ae8746c79f63b530c8d7cb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee3e784a1854227b1d4f1bf5e56ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4e8d2c666f4b61a32b2e126fafa182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbfe76dbdb649d9bf48ccd3256a3da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6429cc9517d74a31bc421683b9e54418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92dda8054254113a31c3706593da9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61865ad9554a5cbd203d901dba3ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79162d8dd57c4a0b8e4e4343c9902b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7cfbbceca14e2ba9b9d7cb43bad4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i d o t h i n k i n i n t h e s h o r t t e r m s e t t i n g s o m e t\n",
      "h i n g u p c o u l d b e s u p e r c o o l. s o m e o n e e l s e m e\n",
      "n t i o n e d t h a t 9 h u g o b o w n e - a n d e r s o n : w i t h r\n",
      "e s p e c t t o t h e t o o l o v e r w h e l m, i t ' d b e g r e a t.\n",
      "t h e y d o n ' t t h i n k t h a t n e c e s s a r i l y t h e y ' l l\n",
      "b e a b l e t o u s e a l l o f t h e m b y t h e e n d o f t h e c o u\n",
      "r s e, a n d t h a t ' s n o t a n e x p e c t a t i o n i t ' s m o r\n",
      "e f o\n",
      "\n",
      "Total chunks: 679\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b0a83-5a52-4c79-87fb-873519e083d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import and Setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path if needed\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "\n",
    "from vector_emb import (\n",
    "    answer_question, \n",
    "    llm_answer_question, \n",
    "    get_openai_client,\n",
    "    get_workshop_info,\n",
    "    get_collection_status,\n",
    "    format_sources\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ Imports and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcddb44-ecf6-4e81-8c44-fa51ac496b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 workshops: ['WS5', 'WS2', 'WS1', 'WS3', 'WS4', 'WS6']\n",
      "📚 Available workshops: ['WS5', 'WS2', 'WS1', 'WS3', 'WS4', 'WS6']\n",
      "📊 Total workshops: 6\n",
      "Retrieved existing collection 'workshop_chunks_all'\n",
      "Collection 'workshop_chunks_all' contains 193 total chunks\n",
      "Found 6 workshops: ['WS5', 'WS2', 'WS1', 'WS3', 'WS4', 'WS6']\n",
      "Workshop breakdown:\n",
      "  - WS5: 60 chunks ✓ Processed\n",
      "  - WS2: 1 chunks ✓ Processed\n",
      "  - WS1: 65 chunks ✓ Processed\n",
      "  - WS3: 1 chunks ✓ Processed\n",
      "  - WS4: 1 chunks ✓ Processed\n",
      "  - WS6: 65 chunks ✓ Processed\n",
      "\n",
      "📈 Collection status: {'total_chunks': 193, 'workshop_counts': {'WS5': 60, 'WS2': 1, 'WS1': 65, 'WS3': 1, 'WS4': 1, 'WS6': 65}}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Check Workshop Status\n",
    "# See what workshops are available and if the collection is populated\n",
    "workshop_info = get_workshop_info()\n",
    "print(f\"📚 Available workshops: {workshop_info['workshop_ids']}\")\n",
    "print(f\"📊 Total workshops: {workshop_info['total_workshops']}\")\n",
    "\n",
    "collection_status = get_collection_status()\n",
    "print(f\"\\n📈 Collection status: {collection_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc8070-fcdb-452d-ae27-1c4c21f9f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Simple Q&A Function\n",
    "def ask_question(question, workshop_filter=None, show_sources=True):\n",
    "    \"\"\"\n",
    "    Ask a question and get an answer from the workshop transcripts\n",
    "    \n",
    "    Args:\n",
    "        question (str): Your question\n",
    "        workshop_filter (str or list): Filter by specific workshop(s), e.g., \"WS1\" or [\"WS1\", \"WS2\"]\n",
    "        show_sources (bool): Whether to display source information\n",
    "    \"\"\"\n",
    "    print(f\"🤔 Question: {question}\")\n",
    "    if workshop_filter:\n",
    "        print(f\"🎯 Filtering by workshop(s): {workshop_filter}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get relevant context and sources\n",
    "        context, sources, chunks = answer_question(question, workshop_filter=workshop_filter)\n",
    "        \n",
    "        if not context:\n",
    "            print(\"❌ No relevant context found for your question.\")\n",
    "            return\n",
    "        \n",
    "        # Generate LLM answer\n",
    "        client = get_openai_client()\n",
    "        answer, context_info = llm_answer_question(client, context, sources, chunks, question)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"🤖 Answer:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(answer)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        if show_sources:\n",
    "            print(\"📚 Sources:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(format_sources([{\n",
    "                'workshop_id': source['workshop_id'],\n",
    "                'position': source['position'],\n",
    "                'speaker': source['speaker'],\n",
    "                'text': source['text'][:200] + \"...\" if len(source['text']) > 200 else source['text']\n",
    "            } for source in sources]))\n",
    "        \n",
    "        print(\"\\n📊 Context Info:\")\n",
    "        print(f\"- Chunks used: {context_info['num_chunks']}\")\n",
    "        print(f\"- Workshops referenced: {', '.join(context_info['workshops_used'])}\")\n",
    "        print(f\"- Context tokens: {context_info['context_tokens']}\")\n",
    "        print(f\"- Completion tokens: {context_info['completion_tokens']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "\n",
    "# Test the function\n",
    "ask_question(\"What is the main topic covered in the workshops?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de17440-fccd-46f3-b2a1-34b40fcdd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Interactive Q&A Loop\n",
    "def interactive_qa():\n",
    "    \"\"\"Run an interactive Q&A session\"\"\"\n",
    "    print(\"🎓 Workshop Q&A Session Started!\")\n",
    "    print(\"Type 'quit' to exit, 'workshops' to see available workshops\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\n💭 Your question: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"👋 Goodbye!\")\n",
    "            break\n",
    "        elif question.lower() == 'workshops':\n",
    "            info = get_workshop_info()\n",
    "            print(f\"Available workshops: {', '.join(info['workshop_ids'])}\")\n",
    "            continue\n",
    "        elif not question:\n",
    "            continue\n",
    "        \n",
    "        # Check if user wants to filter by workshop\n",
    "        workshop_filter = None\n",
    "        if question.startswith('@'):\n",
    "            parts = question.split(' ', 1)\n",
    "            if len(parts) == 2:\n",
    "                workshop_filter = parts[0][1:]  # Remove @ symbol\n",
    "                question = parts[1]\n",
    "                print(f\"🎯 Filtering by workshop: {workshop_filter}\")\n",
    "        \n",
    "        ask_question(question, workshop_filter=workshop_filter, show_sources=False)\n",
    "\n",
    "# Uncomment the line below to start interactive mode\n",
    "# interactive_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1113e-7c12-458f-9283-195ad460f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Specific Workshop Questions\n",
    "# Example of asking questions about specific workshops\n",
    "\n",
    "# Ask about a specific workshop\n",
    "ask_question(\"What are the key concepts covered?\", workshop_filter=\"WS1\")\n",
    "\n",
    "# Ask about multiple workshops\n",
    "ask_question(\"What are the differences between the approaches?\", workshop_filter=[\"WS1\", \"WS2\"])\n",
    "\n",
    "# General question across all workshops\n",
    "ask_question(\"What are the most important takeaways?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

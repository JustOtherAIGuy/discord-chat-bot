{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('src')  # Add src directory to path\n",
    "\n",
    "from vector_emb import (\n",
    "    discover_workshops, \n",
    "    process_all_workshops, \n",
    "    get_collection_status,\n",
    "    answer_question,\n",
    "    llm_answer_question,\n",
    "    get_openai_client,\n",
    "    retrieve_relevant_chunks,\n",
    "    get_context_for_question,\n",
    "    combine_chunks,\n",
    "    format_sources\n",
    ")\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Check Workshop Discovery\n",
    "print(\"üîç Discovering Workshop Files...\")\n",
    "workshops = discover_workshops()\n",
    "\n",
    "if workshops:\n",
    "    print(f\"\\nFound {len(workshops)} workshop files:\")\n",
    "    for workshop_id, info in workshops.items():\n",
    "        print(f\"  üìÑ {workshop_id}: {info['filename']}\")\n",
    "        print(f\"     Path: {info['path']}\")\n",
    "        print(f\"     Exists: {os.path.exists(info['path'])}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ùå No workshop files found in data directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Process Workshops into Vector Database\n",
    "print(\"üöÄ Processing workshops into vector database...\")\n",
    "print(\"This may take a few minutes for the first run...\\n\")\n",
    "\n",
    "# Process all workshops\n",
    "processed_workshops = process_all_workshops()\n",
    "\n",
    "# Check collection status\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä Collection Status After Processing:\")\n",
    "get_collection_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Interactive Question Answering with Detailed Retrieval\n",
    "def detailed_question_answer(question, workshop_filter=None, show_chunks=True):\n",
    "    \"\"\"Answer a question with detailed retrieval information\"\"\"\n",
    "    \n",
    "    print(f\"‚ùì Question: {question}\")\n",
    "    print(f\"üéØ Workshop Filter: {workshop_filter or 'All workshops'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Step 1: Get context and sources\n",
    "    print(\"üîç Step 1: Retrieving relevant chunks...\")\n",
    "    context, sources, chunks = get_context_for_question(\n",
    "        question=question,\n",
    "        workshop_filter=workshop_filter,\n",
    "        max_chunks=5\n",
    "    )\n",
    "    \n",
    "    print(f\"   üì¶ Retrieved {len(chunks)} chunks\")\n",
    "    print(f\"   üî¢ Context tokens: {len(context.split())}\")\n",
    "    \n",
    "    # Step 2: Show retrieved chunks\n",
    "    if show_chunks:\n",
    "        print(\"\\nüìã Step 2: Retrieved Chunks (ordered by relevance):\")\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            metadata = chunk['metadata']\n",
    "            print(f\"\\n   Chunk {i+1}:\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Workshop: {metadata.get('workshop_id', 'Unknown')}\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Position: {metadata.get('position', 'Unknown')}\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Speaker: {metadata.get('speaker', 'Unknown')}\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Tokens: {metadata.get('token_count', 'Unknown')}\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ Text Preview: {chunk['text'][:200]}...\")\n",
    "    \n",
    "    # Step 3: Show combined context\n",
    "    print(\"\\nüìù Step 3: Combined Context:\")\n",
    "    print(f\"   üìè Total context length: {len(context)} characters\")\n",
    "    print(f\"   üî¢ Estimated tokens: {len(context.split())}\")\n",
    "    \n",
    "    # Step 4: Generate answer\n",
    "    print(\"\\nü§ñ Step 4: Generating answer...\")\n",
    "    client = get_openai_client()\n",
    "    answer, context_info = llm_answer_question(client, context, sources, chunks, question)\n",
    "    \n",
    "    print(f\"\\nüí¨ Answer:\")\n",
    "    print(f\"   {answer}\")\n",
    "    \n",
    "    print(f\"\\nüìä Context Info:\")\n",
    "    for key, value in context_info.items():\n",
    "        if key != 'chunks':  # Don't print the full chunks again\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ {key}: {value}\")\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'context': context,\n",
    "        'sources': sources,\n",
    "        'chunks': chunks,\n",
    "        'context_info': context_info\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = detailed_question_answer(\n",
    "    question=\"What is Modal and how is it used?\",\n",
    "    workshop_filter=None,  # Search all workshops\n",
    "    show_chunks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Compare Different Workshop Filters\n",
    "questions = [\n",
    "    \"What is Modal?\",\n",
    "    \"How do you deploy applications?\", \n",
    "    \"What are the main benefits discussed?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîÑ Testing: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Test with all workshops\n",
    "    print(\"\\nüåç Searching ALL workshops:\")\n",
    "    result_all = detailed_question_answer(question, workshop_filter=None, show_chunks=False)\n",
    "    \n",
    "    # Test with specific workshop (if WS1 exists)\n",
    "    if 'WS1' in discover_workshops():\n",
    "        print(\"\\nüéØ Searching WS1 only:\")\n",
    "        result_ws1 = detailed_question_answer(question, workshop_filter=\"WS1\", show_chunks=False)\n",
    "    \n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'all_workshops': result_all,\n",
    "        'ws1_only': result_ws1 if 'WS1' in discover_workshops() else None\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Analyze Retrieval Patterns\n",
    "def analyze_retrieval_patterns(results):\n",
    "    \"\"\"Analyze which workshops and chunks are being retrieved most often\"\"\"\n",
    "    \n",
    "    workshop_usage = {}\n",
    "    chunk_positions = []\n",
    "    speakers_mentioned = {}\n",
    "    \n",
    "    for result in results:\n",
    "        if 'all_workshops' in result:\n",
    "            sources = result['all_workshops']['sources']\n",
    "            \n",
    "            for source in sources:\n",
    "                # Track workshop usage\n",
    "                workshop_id = source.get('workshop_id', 'Unknown')\n",
    "                workshop_usage[workshop_id] = workshop_usage.get(workshop_id, 0) + 1\n",
    "                \n",
    "                # Track chunk positions\n",
    "                position = source.get('position', 0)\n",
    "                if isinstance(position, (int, str)) and str(position).isdigit():\n",
    "                    chunk_positions.append(int(position))\n",
    "                \n",
    "                # Track speakers\n",
    "                speaker = source.get('speaker', 'Unknown')\n",
    "                speakers_mentioned[speaker] = speakers_mentioned.get(speaker, 0) + 1\n",
    "    \n",
    "    # Create analysis DataFrame\n",
    "    analysis_df = pd.DataFrame([\n",
    "        {'Metric': 'Workshop Usage', 'Data': workshop_usage},\n",
    "        {'Metric': 'Speaker Frequency', 'Data': speakers_mentioned},\n",
    "        {'Metric': 'Chunk Positions', 'Data': f\"Range: {min(chunk_positions) if chunk_positions else 0}-{max(chunk_positions) if chunk_positions else 0}\"}\n",
    "    ])\n",
    "    \n",
    "    print(\"üìà Retrieval Pattern Analysis:\")\n",
    "    print(f\"   üè¢ Workshop Usage: {workshop_usage}\")\n",
    "    print(f\"   üé§ Speaker Frequency: {speakers_mentioned}\")\n",
    "    print(f\"   üìç Chunk Position Range: {min(chunk_positions) if chunk_positions else 0}-{max(chunk_positions) if chunk_positions else 0}\")\n",
    "    \n",
    "    return analysis_df\n",
    "\n",
    "# Run analysis if we have results\n",
    "if 'results' in locals():\n",
    "    analysis = analyze_retrieval_patterns(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Detailed Chunk Inspection\n",
    "def inspect_chunks_in_detail(question, max_chunks=10):\n",
    "    \"\"\"Get detailed view of all retrieved chunks for a question\"\"\"\n",
    "    \n",
    "    print(f\"üî¨ Detailed Chunk Inspection for: '{question}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get more chunks than usual for analysis\n",
    "    chunks = retrieve_relevant_chunks(question, n_results=max_chunks)\n",
    "    \n",
    "    chunk_data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        metadata = chunk['metadata']\n",
    "        \n",
    "        chunk_info = {\n",
    "            'Rank': i + 1,\n",
    "            'Workshop': metadata.get('workshop_id', 'Unknown'),\n",
    "            'Position': metadata.get('position', 'Unknown'),\n",
    "            'Speaker': metadata.get('speaker', 'Unknown'),\n",
    "            'Timestamp': metadata.get('timestamp', 'Unknown'),\n",
    "            'Token_Count': metadata.get('token_count', 'Unknown'),\n",
    "            'Text_Length': len(chunk['text']),\n",
    "            'Text_Preview': chunk['text'][:150] + \"...\" if len(chunk['text']) > 150 else chunk['text']\n",
    "        }\n",
    "        chunk_data.append(chunk_info)\n",
    "    \n",
    "    # Convert to DataFrame for better display\n",
    "    chunks_df = pd.DataFrame(chunk_data)\n",
    "    \n",
    "    print(f\"üìä Found {len(chunks)} chunks:\")\n",
    "    print(chunks_df[['Rank', 'Workshop', 'Position', 'Speaker', 'Token_Count', 'Text_Length']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nüìù Text Previews:\")\n",
    "    for i, chunk_info in enumerate(chunk_data[:5]):  # Show first 5\n",
    "        print(f\"\\n{i+1}. [{chunk_info['Workshop']}] Position {chunk_info['Position']}:\")\n",
    "        print(f\"   {chunk_info['Text_Preview']}\")\n",
    "    \n",
    "    return chunks_df\n",
    "\n",
    "# Example inspection\n",
    "chunks_analysis = inspect_chunks_in_detail(\"What is Modal?\", max_chunks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Test Different Retrieval Parameters\n",
    "def test_retrieval_parameters(question):\n",
    "    \"\"\"Test how different parameters affect retrieval\"\"\"\n",
    "    \n",
    "    print(f\"üß™ Testing Retrieval Parameters for: '{question}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test different chunk counts\n",
    "    chunk_counts = [3, 5, 10]\n",
    "    \n",
    "    for count in chunk_counts:\n",
    "        print(f\"\\nüì¶ Retrieving {count} chunks:\")\n",
    "        chunks = retrieve_relevant_chunks(question, n_results=count)\n",
    "        context = combine_chunks(chunks)\n",
    "        \n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Retrieved: {len(chunks)} chunks\")\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Context tokens: ~{len(context.split())}\")\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Context length: {len(context)} chars\")\n",
    "        \n",
    "        # Show workshop distribution\n",
    "        workshops = [chunk['metadata'].get('workshop_id', 'Unknown') for chunk in chunks]\n",
    "        workshop_dist = {ws: workshops.count(ws) for ws in set(workshops)}\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Workshop distribution: {workshop_dist}\")\n",
    "\n",
    "# Test parameters\n",
    "test_retrieval_parameters(\"How do you use Modal for deployment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: Export Results for Analysis\n",
    "def export_qa_results(results, filename=\"qa_analysis.csv\"):\n",
    "    \"\"\"Export Q&A results to CSV for further analysis\"\"\"\n",
    "    \n",
    "    export_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        question = result['question']\n",
    "        \n",
    "        if 'all_workshops' in result and result['all_workshops']:\n",
    "            qa_data = result['all_workshops']\n",
    "            \n",
    "            export_data.append({\n",
    "                'question': question,\n",
    "                'answer': qa_data['answer'],\n",
    "                'num_chunks': len(qa_data['chunks']),\n",
    "                'context_tokens': qa_data['context_info'].get('context_tokens', 0),\n",
    "                'completion_tokens': qa_data['context_info'].get('completion_tokens', 0),\n",
    "                'workshops_used': ', '.join(qa_data['context_info'].get('workshops_used', [])),\n",
    "                'context_length': len(qa_data['context'])\n",
    "            })\n",
    "    \n",
    "    if export_data:\n",
    "        export_df = pd.DataFrame(export_data)\n",
    "        export_df.to_csv(filename, index=False)\n",
    "        print(f\"üìÑ Exported {len(export_data)} Q&A results to {filename}\")\n",
    "        print(export_df.head())\n",
    "        return export_df\n",
    "    else:\n",
    "        print(\"‚ùå No results to export\")\n",
    "\n",
    "# Export if we have results\n",
    "if 'results' in locals():\n",
    "    qa_df = export_qa_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: Interactive Q&A Session\n",
    "def interactive_qa():\n",
    "    \"\"\"Interactive question-answering session\"\"\"\n",
    "    \n",
    "    print(\"üéØ Interactive Q&A Session\")\n",
    "    print(\"Ask questions about your workshop transcripts!\")\n",
    "    print(\"Type 'quit' to exit, 'status' to check collection status\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Your question: \").strip()\n",
    "        \n",
    "        if question.lower() == 'quit':\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        elif question.lower() == 'status':\n",
    "            get_collection_status()\n",
    "            continue\n",
    "        elif not question:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Get detailed answer\n",
    "            result = detailed_question_answer(question, show_chunks=False)\n",
    "            \n",
    "            # Ask if user wants to see chunks\n",
    "            show_detail = input(\"\\nüîç Show detailed chunk analysis? (y/n): \").lower()\n",
    "            if show_detail == 'y':\n",
    "                inspect_chunks_in_detail(question, max_chunks=5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Uncomment to run interactive session\n",
    "# interactive_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
